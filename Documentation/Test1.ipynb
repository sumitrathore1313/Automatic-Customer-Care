{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Make retrivel chatbot using rnn and aiml data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This test contain following things\n",
    "    1. it will use aiml dataset\n",
    "    2. it will use seq2seq network\n",
    "    3. it will use avg sentence model, 2d sentence model, n-gram 2d sentence model and character quantization model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "data_file = \"/home/sumit/Desktop/project17/Nucleons/Data/aiml_data/filter_all.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23328 [['DEFINE A', 'The first letter of the roman alphabet.'], ['DEFINE AARDVARK', 'An aardvark is a south african ant eating animal.'], ['DEFINE AARDWOLF', 'An aardwolf is a carnivorous mammal.'], ['DEFINE ABA', 'An aba is a sack like garment worn by arabs.'], ['DEFINE ABACUS', 'An abacus is a counting frame.'], ['DEFINE ABBA', 'Abba is a father, it is the title of a bishop in the Syrian, Coptic, and Ethiopian Christian churches.'], ['DEFINE ABBA', 'Abba means father in Hebrew.It is used as an appelation of respect.'], ['DEFINE ABBA', \"Abba was this real cool 'seventies band man.\"], ['DEFINE ABBA', 'Anna, Bjorn, Benny and Agnetha.'], ['DEFINE ABBA', '']]\n"
     ]
    }
   ],
   "source": [
    "from DataPreprocessing.AimlSentenceData import get_simple_sentence_data\n",
    "sentence_data = get_simple_sentence_data(data_file)\n",
    "print len(sentence_data), sentence_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 [array([[-0.10925553,  0.01258286,  0.05610814, ..., -0.0679386 ,\n",
      "        -0.04471166,  0.08036581],\n",
      "       [-0.043387  ,  0.00704899, -0.00324529, ..., -0.07885778,\n",
      "         0.10201535,  0.03787032],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[-0.00656124, -0.04206555,  0.12508174, ..., -0.02506376,\n",
      "         0.14220549,  0.04648907],\n",
      "       [-0.00351714,  0.00656362,  0.06187268, ...,  0.01095418,\n",
      "         0.04966541, -0.05534476],\n",
      "       [-0.00251732, -0.00617778,  0.04505125, ..., -0.05138712,\n",
      "        -0.06569713, -0.00959832],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]])]\n"
     ]
    }
   ],
   "source": [
    "from VectorProcessing import GloveAimlSentenceVector\n",
    "sentence_class = GloveAimlSentenceVector(data_file)\n",
    "#print len(sentence_class.word2vec)\n",
    "sen2vec = sentence_class.get_2D_sentenceVector(sentence_data[0:100])\n",
    "print len(sen2vec), sen2vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Helper import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(sen2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 50, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50, 128)           131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 50, 100)           12900     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 50, 100)           0         \n",
      "=================================================================\n",
      "Total params: 788,068\n",
      "Trainable params: 788,068\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 80 samples, validate on 10 samples\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 92s - loss: -2.5659 - acc: 0.1307 - val_loss: -3.8553 - val_acc: 0.1300\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 31s - loss: -4.6389 - acc: 0.1240 - val_loss: -3.9889 - val_acc: 0.1300\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 32s - loss: -4.6980 - acc: 0.1240 - val_loss: -4.0091 - val_acc: 0.1300\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 35s - loss: -4.7075 - acc: 0.1240 - val_loss: -4.0133 - val_acc: 0.1300\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 34s - loss: -4.7134 - acc: 0.1240 - val_loss: -4.0125 - val_acc: 0.1300\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 35s - loss: -4.7132 - acc: 0.1240 - val_loss: -4.0197 - val_acc: 0.1300\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 36s - loss: -4.7140 - acc: 0.1240 - val_loss: -4.0137 - val_acc: 0.1300\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 31s - loss: -4.7182 - acc: 0.1240 - val_loss: -4.0192 - val_acc: 0.1300\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 33s - loss: -4.7203 - acc: 0.1240 - val_loss: -4.0277 - val_acc: 0.1300\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 31s - loss: -4.7218 - acc: 0.1240 - val_loss: -4.0268 - val_acc: 0.1300\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 35s - loss: -4.7205 - acc: 0.1240 - val_loss: -4.0255 - val_acc: 0.1300\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 54s - loss: -4.7271 - acc: 0.1240 - val_loss: -4.0298 - val_acc: 0.1300\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 32s - loss: -4.7304 - acc: 0.1240 - val_loss: -4.0189 - val_acc: 0.1300\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 33s - loss: -4.7296 - acc: 0.1240 - val_loss: -4.0278 - val_acc: 0.1300\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 34s - loss: -4.7325 - acc: 0.1152 - val_loss: -4.0281 - val_acc: 0.1300\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 32s - loss: -4.7373 - acc: 0.1240 - val_loss: -4.0296 - val_acc: 0.1300\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 30s - loss: -4.7403 - acc: 0.1227 - val_loss: -4.0356 - val_acc: 0.1300\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 32s - loss: -4.7429 - acc: 0.1237 - val_loss: -4.0371 - val_acc: 0.1300\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 30s - loss: -4.7463 - acc: 0.1240 - val_loss: -4.0307 - val_acc: 0.1300\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 32s - loss: -4.7484 - acc: 0.1240 - val_loss: -4.0406 - val_acc: 0.1300\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 31s - loss: -4.7511 - acc: 0.1240 - val_loss: -4.0462 - val_acc: 0.1300\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 34s - loss: -4.7551 - acc: 0.1240 - val_loss: -4.0388 - val_acc: 0.1300\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 32s - loss: -4.7613 - acc: 0.1240 - val_loss: -4.0420 - val_acc: 0.1300\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 32s - loss: -4.7667 - acc: 0.1240 - val_loss: -4.0508 - val_acc: 0.1300\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 31s - loss: -4.7696 - acc: 0.1240 - val_loss: -4.0470 - val_acc: 0.1300\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 32s - loss: -4.7746 - acc: 0.1240 - val_loss: -4.0510 - val_acc: 0.1300\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 30s - loss: -4.7765 - acc: 0.1240 - val_loss: -4.0516 - val_acc: 0.1300\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 36s - loss: -4.7834 - acc: 0.1240 - val_loss: -4.0445 - val_acc: 0.1300\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 30s - loss: -4.7854 - acc: 0.1240 - val_loss: -4.0492 - val_acc: 0.1300\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 30s - loss: -4.7883 - acc: 0.1240 - val_loss: -4.0575 - val_acc: 0.1300\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 33s - loss: -4.7931 - acc: 0.1240 - val_loss: -4.0627 - val_acc: 0.1300\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 33s - loss: -4.7965 - acc: 0.1240 - val_loss: -4.0526 - val_acc: 0.1300\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 32s - loss: -4.7953 - acc: 0.1240 - val_loss: -4.0588 - val_acc: 0.1300\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 30s - loss: -4.7998 - acc: 0.1240 - val_loss: -4.0601 - val_acc: 0.1300\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 33s - loss: -4.8021 - acc: 0.1227 - val_loss: -4.0641 - val_acc: 0.1300\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 35s - loss: -4.8044 - acc: 0.1240 - val_loss: -4.0568 - val_acc: 0.1300\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 34s - loss: -4.8060 - acc: 0.1240 - val_loss: -4.0540 - val_acc: 0.1300\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 33s - loss: -4.8086 - acc: 0.1240 - val_loss: -4.0566 - val_acc: 0.1300\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 31s - loss: -4.8077 - acc: 0.1240 - val_loss: -4.0662 - val_acc: 0.1300\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 33s - loss: -4.8087 - acc: 0.1240 - val_loss: -4.0659 - val_acc: 0.1300\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 33s - loss: -4.8109 - acc: 0.1240 - val_loss: -4.0626 - val_acc: 0.1300\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 30s - loss: -4.8119 - acc: 0.1240 - val_loss: -4.0641 - val_acc: 0.1300\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 33s - loss: -4.8115 - acc: 0.1240 - val_loss: -4.0583 - val_acc: 0.1300\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 35s - loss: -4.8139 - acc: 0.1240 - val_loss: -4.0682 - val_acc: 0.1300\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 32s - loss: -4.8158 - acc: 0.1240 - val_loss: -4.0549 - val_acc: 0.1300\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 34s - loss: -4.8181 - acc: 0.1240 - val_loss: -4.0590 - val_acc: 0.1300\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 33s - loss: -4.8184 - acc: 0.1240 - val_loss: -4.0443 - val_acc: 0.1300\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 33s - loss: -4.8176 - acc: 0.1240 - val_loss: -4.0662 - val_acc: 0.1300\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 30s - loss: -4.8187 - acc: 0.1240 - val_loss: -4.0672 - val_acc: 0.1300\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 33s - loss: -4.8199 - acc: 0.1240 - val_loss: -4.0596 - val_acc: 0.1300\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 31s - loss: -4.8211 - acc: 0.1227 - val_loss: -4.0581 - val_acc: 0.1300\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 33s - loss: -4.8214 - acc: 0.1240 - val_loss: -4.0605 - val_acc: 0.1300\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 30s - loss: -4.8258 - acc: 0.1240 - val_loss: -4.0500 - val_acc: 0.1300\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 30s - loss: -4.8231 - acc: 0.1240 - val_loss: -4.0609 - val_acc: 0.1300\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 39s - loss: -4.8249 - acc: 0.1240 - val_loss: -4.0595 - val_acc: 0.1300\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 30s - loss: -4.8251 - acc: 0.1240 - val_loss: -4.0625 - val_acc: 0.1300\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 30s - loss: -4.8285 - acc: 0.1240 - val_loss: -4.0573 - val_acc: 0.1300\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 30s - loss: -4.8259 - acc: 0.1240 - val_loss: -4.0611 - val_acc: 0.1300\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 30s - loss: -4.8276 - acc: 0.1240 - val_loss: -4.0590 - val_acc: 0.1300\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 32s - loss: -4.8284 - acc: 0.1240 - val_loss: -4.0542 - val_acc: 0.1300\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 30s - loss: -4.8275 - acc: 0.1240 - val_loss: -4.0604 - val_acc: 0.1300\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 32s - loss: -4.8259 - acc: 0.1240 - val_loss: -4.0607 - val_acc: 0.1300\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 30s - loss: -4.8307 - acc: 0.1235 - val_loss: -4.0598 - val_acc: 0.1300\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 32s - loss: -4.8297 - acc: 0.1240 - val_loss: -4.0555 - val_acc: 0.1300\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 30s - loss: -4.8294 - acc: 0.1240 - val_loss: -4.0541 - val_acc: 0.1300\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 30s - loss: -4.8271 - acc: 0.1240 - val_loss: -4.0554 - val_acc: 0.1300\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 30s - loss: -4.8300 - acc: 0.1240 - val_loss: -4.0629 - val_acc: 0.1300\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 31s - loss: -4.8326 - acc: 0.1240 - val_loss: -4.0514 - val_acc: 0.1300\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 29s - loss: -4.8314 - acc: 0.1240 - val_loss: -4.0608 - val_acc: 0.1300\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 30s - loss: -4.8321 - acc: 0.1240 - val_loss: -4.0689 - val_acc: 0.1300\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 32s - loss: -4.8324 - acc: 0.1235 - val_loss: -4.0662 - val_acc: 0.1300\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 30s - loss: -4.8358 - acc: 0.1235 - val_loss: -4.0614 - val_acc: 0.1300\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 31s - loss: -4.8315 - acc: 0.1240 - val_loss: -4.0630 - val_acc: 0.1300\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 31s - loss: -4.8339 - acc: 0.1240 - val_loss: -4.0546 - val_acc: 0.1300\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 31s - loss: -4.8341 - acc: 0.1240 - val_loss: -4.0610 - val_acc: 0.1300\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 29s - loss: -4.8328 - acc: 0.1240 - val_loss: -4.0584 - val_acc: 0.1300\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 34s - loss: -4.8311 - acc: 0.1240 - val_loss: -4.0614 - val_acc: 0.1300\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 29s - loss: -4.8351 - acc: 0.1240 - val_loss: -4.0613 - val_acc: 0.1300\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 29s - loss: -4.8363 - acc: 0.1240 - val_loss: -4.0553 - val_acc: 0.1300\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 31s - loss: -4.8360 - acc: 0.1240 - val_loss: -4.0535 - val_acc: 0.1300\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 29s - loss: -4.8357 - acc: 0.1240 - val_loss: -4.0587 - val_acc: 0.1300\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 31s - loss: -4.8369 - acc: 0.1240 - val_loss: -4.0585 - val_acc: 0.1300\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 31s - loss: -4.8376 - acc: 0.1240 - val_loss: -4.0568 - val_acc: 0.1300\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 31s - loss: -4.8351 - acc: 0.1240 - val_loss: -4.0596 - val_acc: 0.1300\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 29s - loss: -4.8388 - acc: 0.1240 - val_loss: -4.0595 - val_acc: 0.1300\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 31s - loss: -4.8389 - acc: 0.1235 - val_loss: -4.0661 - val_acc: 0.1300\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 31s - loss: -4.8398 - acc: 0.1240 - val_loss: -4.0560 - val_acc: 0.1300\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 31s - loss: -4.8388 - acc: 0.1240 - val_loss: -4.0551 - val_acc: 0.1300\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 31s - loss: -4.8398 - acc: 0.1240 - val_loss: -4.0610 - val_acc: 0.1300\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 29s - loss: -4.8374 - acc: 0.1240 - val_loss: -4.0595 - val_acc: 0.1300\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 31s - loss: -4.8414 - acc: 0.1232 - val_loss: -4.0564 - val_acc: 0.1300\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 31s - loss: -4.8395 - acc: 0.1240 - val_loss: -4.0658 - val_acc: 0.1300\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 31s - loss: -4.8400 - acc: 0.1240 - val_loss: -4.0624 - val_acc: 0.1300\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 29s - loss: -4.8408 - acc: 0.1240 - val_loss: -4.0666 - val_acc: 0.1300\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 29s - loss: -4.8419 - acc: 0.1240 - val_loss: -4.0604 - val_acc: 0.1300\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 29s - loss: -4.8445 - acc: 0.1227 - val_loss: -4.0554 - val_acc: 0.1300\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 31s - loss: -4.8424 - acc: 0.1240 - val_loss: -4.0592 - val_acc: 0.1300\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 31s - loss: -4.8424 - acc: 0.1240 - val_loss: -4.0679 - val_acc: 0.1300\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 29s - loss: -4.8414 - acc: 0.1240 - val_loss: -4.0573 - val_acc: 0.1300\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 29s - loss: -4.8442 - acc: 0.1240 - val_loss: -4.0537 - val_acc: 0.1300\n"
     ]
    }
   ],
   "source": [
    "from Models.Regression import seq2seq\n",
    "model = seq2seq(train_x, train_y, test_x[0:10], test_y[0:10], epochs=100, BATCH_SIZE = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.16146070e-08   4.16202829e-06   2.48623043e-02 ...,   3.33640884e-08\n",
      "    3.75445038e-02   2.62566336e-05]\n",
      " [  1.30334882e-10   9.00766579e-04   4.92709316e-02 ...,   4.09290324e-10\n",
      "    5.41128144e-02   1.22670259e-03]\n",
      " [  9.58850100e-12   9.96815693e-03   4.25665900e-02 ...,   4.52925510e-11\n",
      "    4.77092937e-02   1.59368701e-02]\n",
      " ..., \n",
      " [  9.00987997e-13   9.26285144e-03   2.68891808e-02 ...,   5.29152807e-12\n",
      "    6.39719814e-02   1.92875706e-03]\n",
      " [  9.00987997e-13   9.26285144e-03   2.68891808e-02 ...,   5.29152807e-12\n",
      "    6.39719814e-02   1.92875706e-03]\n",
      " [  9.00987997e-13   9.26285144e-03   2.68891808e-02 ...,   5.29152807e-12\n",
      "    6.39719814e-02   1.92875706e-03]]\n"
     ]
    }
   ],
   "source": [
    "avera = sum(train_y[0]-y_pred[0])\n",
    "print y_pred[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
